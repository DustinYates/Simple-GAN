{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "Based on [DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow) by [Taehoon Kim](https://github.com/carpedm20) on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, time\n",
    "from glob import glob\n",
    "\n",
    "from ops import batch_norm, linear, conv2d, deconv2d, lrelu\n",
    "from image_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_crop = True\n",
    "batch_size = 64\n",
    "image_size = 108\n",
    "sample_size = 64\n",
    "image_shape = [64, 64, 3]\n",
    "\n",
    "z_dim = 100\n",
    "\n",
    "gf_dim = 64\n",
    "df_dim = 64\n",
    "\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "dataset = \"celebA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_bn1 = batch_norm(name='d_bn1')\n",
    "d_bn2 = batch_norm(name='d_bn2')\n",
    "d_bn3 = batch_norm(name='d_bn3')\n",
    "\n",
    "g_bn0 = batch_norm(name='g_bn0')\n",
    "g_bn1 = batch_norm(name='g_bn1')\n",
    "g_bn2 = batch_norm(name='g_bn2')\n",
    "g_bn3 = batch_norm(name='g_bn3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(image, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    h0 = lrelu(conv2d(image, df_dim, name='d_h0_conv'))\n",
    "    h1 = lrelu(d_bn1(conv2d(h0, df_dim*2, name='d_h1_conv')))\n",
    "    h2 = lrelu(d_bn2(conv2d(h1, df_dim*4, name='d_h2_conv')))\n",
    "    h3 = lrelu(d_bn3(conv2d(h2, df_dim*8, name='d_h3_conv')))\n",
    "    h4 = linear(tf.reshape(h3, [batch_size, -1]), 1, 'd_h3_lin')\n",
    "\n",
    "    return tf.nn.sigmoid(h4), h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    z_ = linear(z, gf_dim*8*4*4, 'g_h0_lin')\n",
    "\n",
    "    h0 = tf.nn.relu(g_bn0(tf.reshape(z_, [-1, 4, 4, gf_dim * 8])))\n",
    "    h1 = tf.nn.relu(g_bn1(deconv2d(h0, [batch_size, 8, 8, gf_dim*4], name='g_h1')))\n",
    "    h2 = tf.nn.relu(g_bn2(deconv2d(h1, [batch_size, 16, 16, gf_dim*2], name='g_h2')))\n",
    "    h3 = tf.nn.relu(g_bn3(deconv2d(h2, [batch_size, 32, 32, gf_dim*1], name='g_h3')))\n",
    "    h4 = deconv2d(h3, [batch_size, 64, 64, 3], name='g_h4')\n",
    "\n",
    "    return tf.nn.tanh(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(tf.float32, [batch_size] + image_shape, name='real_images')\n",
    "sample_images= tf.placeholder(tf.float32, [sample_size] + image_shape, name='sample_images')\n",
    "z = tf.placeholder(tf.float32, [None, z_dim], name='z')\n",
    "\n",
    "G = generator(z)\n",
    "D, D_logits = discriminator(images)\n",
    "D_, D_logits_ = discriminator(G, reuse=True)\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(D_logits, tf.ones_like(D)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(D_logits_, tf.zeros_like(D_)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(D_logits_, tf.ones_like(D_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "\n",
    "d_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "g_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = glob(os.path.join('data', dataset, '*.jpg'))\n",
    "\n",
    "d_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "g_optim = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "sample_z = np.random.uniform(-1, 1, size=(sample_size , z_dim))\n",
    "sample_files = data[0:sample_size]\n",
    "sample = [get_image(sample_file, image_size, is_crop=is_crop) for sample_file in sample_files]\n",
    "sample_images = np.reshape(np.array(sample).astype(np.float32), [sample_size] + image_shape)\n",
    "\n",
    "counter = 1\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10):\n",
    "    data = glob(os.path.join('data', dataset, '*.jpg'))\n",
    "    np.random.shuffle(data)\n",
    "    batch_idxs = len(data)/batch_size\n",
    "\n",
    "    for idx in range(batch_idxs):\n",
    "        batch_files = data[idx*batch_size:(idx+1)*batch_size]\n",
    "        batch = [get_image(batch_file, image_size, is_crop=is_crop) for batch_file in batch_files]\n",
    "        batch_images = np.reshape(np.array(batch).astype(np.float32), [batch_size] + image_shape)\n",
    "\n",
    "        batch_z = np.random.uniform(-1, 1, [batch_size, z_dim]).astype(np.float32)\n",
    "\n",
    "        # Update D network\n",
    "        sess.run([d_optim], feed_dict={images: batch_images, z: batch_z})\n",
    "\n",
    "        # Update G network\n",
    "        sess.run([g_optim], feed_dict={z: batch_z})\n",
    "\n",
    "        # Run g_optim twice to make sure that d_loss does not go to zero (different from paper)\n",
    "        sess.run([g_optim], feed_dict={z: batch_z})\n",
    "\n",
    "        errD_fake = d_loss_fake.eval({z: batch_z}, session=sess)\n",
    "        errD_real = d_loss_real.eval({images: batch_images}, session=sess)\n",
    "        errG = g_loss.eval({z: batch_z}, session=sess)\n",
    "\n",
    "        counter += 1\n",
    "        print('Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f' \\\n",
    "            % (epoch, idx, batch_idxs, time.time() - start_time, errD_fake+errD_real, errG))\n",
    "\n",
    "        if np.mod(counter, 100) == 1:\n",
    "            samples, dl, gl = sess.run([G, d_loss, g_loss], feed_dict={z: sample_z, images: sample_images})\n",
    "            save_images(samples, [8, 8], './samples/train_%s_%s.png' % (epoch, idx))\n",
    "            print('[Sample] d_loss: %.8f, g_loss: %.8f' % (dl, gl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
